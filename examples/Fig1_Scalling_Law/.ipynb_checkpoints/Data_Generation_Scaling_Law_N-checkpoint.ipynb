{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "noble-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import models as TF_model\n",
    "import data_generator as TF_data\n",
    "import utilis as TF_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-convergence",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "In this workflow, we show how to generate data with varying context length (m) in the test dataset. This corresponds to the result in Fig 1. A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = [5]\n",
    "n_list = [500]\n",
    "N_list = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
    "m_list = [5000, 10000, 20000]\n",
    "\n",
    "tau = 5\n",
    "alpha = 3\n",
    "total_num_test = 1000 # tasks num for valid: N_valid\n",
    "total_sep_num_train = 1 # number of different data per tasks: m\n",
    "total_sep_num_valid = 1 # number of different data per tasks: m\n",
    "total_sep_num_test = 1 # number of different data per tasks (out of domain test)\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(len(d_list)):\n",
    "    print(\"d=\" + str(d_list[i]))\n",
    "    input_dim = d_list[i] # d  \n",
    "    A_list_test = TF_data.get_random_invertible_matrix(input_dim, total_num_test, matrix_type=\"Galerkin\",tau=tau,alpha=alpha,seed_value=500) # for test\n",
    "    test_loss_array_pred_d_temp = []\n",
    "    A_list_inv = []\n",
    "    for z in range(len(A_list_test)):\n",
    "        A_list_inv.append(np.linalg.inv(A_list_test[z]))\n",
    "    A_list_inv_np = np.array(A_list_inv)\n",
    "\n",
    "    for N_index in range(len(N_list)):\n",
    "        print(\"N=\" + str(N_list[N_index]))\n",
    "        total_num_train = N_list[N_index]\n",
    "        for j in range(len(n_list)):\n",
    "            print(\"n=\" + str(n_list[j]))\n",
    "            incontext_len = n_list[j]\n",
    "            best_model_path = \".pkl\"\n",
    "            try:\n",
    "                for m_index in range(len(m_list)):\n",
    "                    incontext_len_test = m_list[m_index]\n",
    "                \n",
    "                    input_test, output_test = TF_data.generate_data(A_list_test, input_dim, total_sep_num_test+incontext_len_test, cv_matrix=None, seed_value=600)\n",
    "                    input_test_np = np.array(input_test) \n",
    "                    output_test_np = np.array(output_test) \n",
    "                    \n",
    "                    device = \"cpu\"\n",
    "                            \n",
    "                    model = TF_model.TF_linear_att(incontext_len_test, input_dim, device=device)\n",
    "                    model.load_state_dict(torch.load(best_model_path))\n",
    "                    P = np.array(model.params[0].detach())\n",
    "                    Q = np.array(model.params[1].detach())\n",
    "                    \n",
    "                    Y_temp = input_test_np[:,:-1,:].transpose((0,2,1))\n",
    "                    Y_n = np.einsum(\"abc,acd->abd\", Y_temp, Y_temp.transpose((0,2,1)))\n",
    "                    Y_n = Y_n / incontext_len_test #Y_temp.shape[1]\n",
    "                    input_ = np.einsum(\"abc,acd->abd\", A_list_inv_np, Y_n)\n",
    "                    pred = np.einsum(\"ab,dbe->dae\", P, input_)\n",
    "                    pred = np.einsum(\"dab,bc->dac\", pred, Q)\n",
    "                    pred = np.einsum(\"dab,db->da\", pred, input_test_np[:,-1,:])\n",
    "                    err_temp = np.mean(np.sum((pred - output_test_np[:,-1,:])**2,axis=1))\n",
    "                    \n",
    "                    data_temp = [input_dim, incontext_len, total_num_train, total_num_test, incontext_len_test, err_temp, np.log10(err_temp)]\n",
    "                    data_list.append(data_temp)\n",
    "            except: \n",
    "                print(\"No such file .pkl\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"N_test.npy\", np.array(data_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Tensor_FORCE)",
   "language": "python",
   "name": "my_tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
